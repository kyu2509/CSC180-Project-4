{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katrina Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3578, 7)\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2004-08-19  49.676899  51.693783  47.669952  49.845802  49.845802  44994500\n",
      "1  2004-08-20  50.178635  54.187561  49.925285  53.805050  53.805050  23005800\n",
      "2  2004-08-23  55.017166  56.373344  54.172661  54.346527  54.346527  18393200\n",
      "3  2004-08-24  55.260582  55.439419  51.450363  52.096165  52.096165  15361800\n",
      "4  2004-08-25  52.140873  53.651051  51.604362  52.657513  52.657513   9257400\n",
      "(3578, 6)\n",
      "        Open       High        Low   In Close    Volume  Out Close\n",
      "0  49.676899  51.693783  47.669952  49.845802  44994500  49.845802\n",
      "1  50.178635  54.187561  49.925285  53.805050  23005800  53.805050\n",
      "2  55.017166  56.373344  54.172661  54.346527  18393200  54.346527\n",
      "3  55.260582  55.439419  51.450363  52.096165  15361800  52.096165\n",
      "4  52.140873  53.651051  51.604362  52.657513   9257400  52.657513\n",
      "In Close:\n",
      "\n",
      "         In Close\n",
      "0       49.845802\n",
      "1       53.805050\n",
      "2       54.346527\n",
      "3       52.096165\n",
      "4       52.657513\n",
      "...           ...\n",
      "3573  1071.469971\n",
      "3574  1020.080017\n",
      "3575  1036.209961\n",
      "3576  1076.770020\n",
      "3577  1070.000000\n",
      "\n",
      "[3578 rows x 1 columns]\n",
      "Out Close:\n",
      "\n",
      "        Out Close\n",
      "0       49.845802\n",
      "1       53.805050\n",
      "2       54.346527\n",
      "3       52.096165\n",
      "4       52.657513\n",
      "...           ...\n",
      "3573  1071.469971\n",
      "3574  1020.080017\n",
      "3575  1036.209961\n",
      "3576  1076.770020\n",
      "3577  1070.000000\n",
      "\n",
      "[3578 rows x 1 columns]\n",
      "        Open       High        Low   In Close    Volume  Out Close\n",
      "0  49.676899  51.693783  47.669952  49.845802  44994500  49.845802\n",
      "1  50.178635  54.187561  49.925285  53.805050  23005800  53.805050\n",
      "2  55.017166  56.373344  54.172661  54.346527  18393200  54.346527\n",
      "3  55.260582  55.439419  51.450363  52.096165  15361800  52.096165\n",
      "4  52.140873  53.651051  51.604362  52.657513   9257400  52.657513\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/\"\n",
    "\n",
    "df = pd.read_csv(path + \"GOOG.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df[0:5])\n",
    "\n",
    "# Dropping date and Adj Close, not needed\n",
    "df.drop(columns={\"Date\", \"Adj Close\"}, inplace=True)\n",
    "\n",
    "out_close = df[[\"Close\"]]\n",
    "\n",
    "# Close Feature for Input\n",
    "df.rename(columns={\"Close\": \"In Close\"}, inplace=True)\n",
    "df = pd.concat([df, out_close], axis=1)\n",
    "\n",
    "# Close Feature for Output\n",
    "df.rename(columns={\"Close\": \"Out Close\"}, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df[0:5])\n",
    "\n",
    "# Close Feature for Input\n",
    "print(\"In Close:\\n\")\n",
    "print(df[[\"In Close\"][0:5]])\n",
    "\n",
    "# Close Feature for Output\n",
    "print(\"Out Close:\\n\")\n",
    "print(df[[\"Out Close\"][0:5]])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data\n",
    "Katrina Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Open       High        Low   In Close    Volume  Out Close\n",
      "0  49.676899  51.693783  47.669952  49.845802  44994500  49.845802\n",
      "1  50.178635  54.187561  49.925285  53.805050  23005800  53.805050\n",
      "2  55.017166  56.373344  54.172661  54.346527  18393200  54.346527\n",
      "3  55.260582  55.439419  51.450363  52.096165  15361800  52.096165\n",
      "4  52.140873  53.651051  51.604362  52.657513   9257400  52.657513\n",
      "(3578, 6)\n",
      "       Open      High       Low  In Close    Volume  Out Close\n",
      "0 -1.334844 -1.331443 -1.337457 -1.333645  4.533247  49.845802\n",
      "1 -1.333101 -1.322843 -1.329562 -1.319893  1.870138  53.805050\n",
      "2 -1.316291 -1.315305 -1.314693 -1.318012  1.311494  54.346527\n",
      "3 -1.315446 -1.318526 -1.324223 -1.325828  0.944353  52.096165\n",
      "4 -1.326284 -1.324693 -1.323684 -1.323879  0.205033  52.657513\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "# Numeric Features\n",
    "numeric_feats = [\"Open\", \"High\", \"Low\", \"In Close\", \"Volume\"]\n",
    "\n",
    "# Data Normalization for Input Features, so exclude \"Out Close\"\n",
    "for i in numeric_feats:\n",
    "    encode_numeric_zscore(df, i)\n",
    "    \n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split for Training & Testing\n",
    "Katrina Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2504, 6)\n",
      "(1074, 6)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x,y = to_xy(df, \"Out Close\")\n",
    "\n",
    "print(x, x.shape)\n",
    "print(y, y.shape) \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(\"shape: \\n\")\n",
    "print(df[\"Open\"].shape[0])\n",
    "'''\n",
    "# Splitting 70% of data for Training & 30% for Testing\n",
    "split_index = floor((df[\"Open\"].shape[0])*0.70)\n",
    "\n",
    "df_train = df[0:split_index]\n",
    "df_test = df[split_index:]\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence data to create x and y in the format RNN likes.\n",
    "Katrina Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(seq_size, data):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_size-1):\n",
    "        #print(i)\n",
    "        window = data.iloc[i:(i+seq_size)][[\"Open\", \"High\", \"Low\", \"In Close\", \"Volume\"]].values\n",
    "        after_window = data.iloc[i+seq_size][\"Out Close\"]\n",
    "        #window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2504\n",
      "Shape of x_train: (2496, 7, 5)\n",
      "Shape of x_test: (1066, 7, 5)\n",
      "Shape of y_train: (2496,)\n",
      "Shape of y_test: (1066,)\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "\n",
    "# Past 7 days used for prediction\n",
    "SEQUENCE_SIZE = 7\n",
    "x_train,y_train = to_sequences(SEQUENCE_SIZE, df_train)\n",
    "x_test,y_test = to_sequences(SEQUENCE_SIZE, df_test)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))\n",
    "\n",
    "#print(\"x_train:\\n {}\".format(x_train[0:3]))\n",
    "\n",
    "#print(\"y_train:\\n {}\".format(y_train[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RNN Model using LSTM\n",
    "Katrina Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 - 2s - loss: 49750.3633 - val_loss: 461699.5000 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 2585.7500 - val_loss: 301394.0938 - 550ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 618.6409 - val_loss: 214587.2656 - 521ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 0s - loss: 297.8044 - val_loss: 161553.1719 - 476ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 0s - loss: 200.2098 - val_loss: 107346.1406 - 483ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 0s - loss: 196.6184 - val_loss: 155087.0469 - 428ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 0s - loss: 170.2458 - val_loss: 76032.9844 - 491ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 0s - loss: 144.1667 - val_loss: 96674.4297 - 408ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 0s - loss: 121.7305 - val_loss: 103289.2734 - 407ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 0s - loss: 132.8250 - val_loss: 90307.9219 - 422ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 0s - loss: 146.5761 - val_loss: 58378.8750 - 444ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 0s - loss: 123.1736 - val_loss: 97258.5469 - 495ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 0s - loss: 121.0291 - val_loss: 93606.6016 - 467ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 0s - loss: 101.9829 - val_loss: 73864.6406 - 447ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 0s - loss: 101.7933 - val_loss: 84182.1250 - 427ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 0s - loss: 113.2143 - val_loss: 103603.2109 - 451ms/epoch - 6ms/step\n",
      "Epoch 16: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 2s - loss: 53115.6328 - val_loss: 432796.5000 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 2789.4731 - val_loss: 193571.2812 - 534ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 487.8300 - val_loss: 91971.6719 - 649ms/epoch - 8ms/step\n",
      "Epoch 4/100\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "for i in range(3):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, input_shape=(SEQUENCE_SIZE,5), activation=\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(64))\n",
    "    #model.add(Dropout(0.1))\n",
    "    #model.add(Dense(32))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "    monitor = EarlyStopping(monitor=\"val_loss\", min_delta=1e-3, patience=5, verbose=1, mode=\"auto\")\n",
    "    checkpointer = ModelCheckpoint(filepath=\"models/lstm_checkpoint.keras\", verbose=0, save_best_only=True)\n",
    "\n",
    "    model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor, checkpointer], verbose=2, epochs=100)  \n",
    "    \n",
    "model.load_weights('models/lstm_checkpoint.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 2ms/step\n",
      "(1066, 1) (1066,)\n",
      "Score (RMSE): 123.04219706133296\n",
      "R2: 0.6597219444047588\n",
      "MSE: 15139.382257679894\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "print(pred.shape, y_test.shape)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "print(\"R2:\",metrics.r2_score(y_test,pred))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/100\n",
      "79/79 - 2s - loss: 86000.5078 - val_loss: 672739.3125 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 62634.6172 - val_loss: 415647.0312 - 248ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 0s - loss: 38186.9219 - val_loss: 44522.5234 - 288ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 17266.7188 - val_loss: 364461.0625 - 244ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 8712.8877 - val_loss: 417223.1562 - 239ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 6150.9443 - val_loss: 234733.9062 - 227ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 4297.3828 - val_loss: 130485.1172 - 306ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 3044.2412 - val_loss: 80006.0000 - 255ms/epoch - 3ms/step\n",
      "Epoch 8: early stopping\n",
      "Epoch 1/100\n",
      "79/79 - 2s - loss: 85973.5156 - val_loss: 674502.2500 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 63246.0742 - val_loss: 405840.2500 - 275ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 0s - loss: 37698.4023 - val_loss: 38966.3477 - 305ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 16851.3984 - val_loss: 429931.1562 - 261ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 8678.8809 - val_loss: 404865.0000 - 267ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 6039.8350 - val_loss: 258842.8594 - 262ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 4298.4478 - val_loss: 135573.4531 - 268ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 2858.4438 - val_loss: 81629.7500 - 355ms/epoch - 4ms/step\n",
      "Epoch 8: early stopping\n",
      "Epoch 1/100\n",
      "79/79 - 2s - loss: 86302.3047 - val_loss: 664936.9375 - 2s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 64082.9805 - val_loss: 338042.7812 - 257ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 0s - loss: 36690.8008 - val_loss: 52860.7617 - 305ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 16379.5000 - val_loss: 572157.8750 - 325ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 9201.8877 - val_loss: 458779.6875 - 261ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 6611.3242 - val_loss: 232041.8125 - 244ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 4704.3555 - val_loss: 119031.9844 - 235ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 3426.9058 - val_loss: 68368.3828 - 220ms/epoch - 3ms/step\n",
      "Epoch 8: early stopping\n",
      "34/34 [==============================] - 1s 1ms/step\n",
      "Model: 1\n",
      "Score (RMSE): 229.9146928423905\n",
      "R2: -0.18581990245299496\n",
      "MSE: 52860.76598481077\n",
      "3\n",
      "Epoch 1/100\n",
      "79/79 - 2s - loss: 73462.6797 - val_loss: 602807.1875 - 2s/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 13349.1904 - val_loss: 489660.1875 - 334ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 0s - loss: 2844.7488 - val_loss: 151550.6719 - 383ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 1184.8911 - val_loss: 70205.2656 - 395ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 615.0622 - val_loss: 42696.8125 - 371ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 385.2611 - val_loss: 33244.1758 - 362ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 327.9641 - val_loss: 33712.9102 - 326ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 310.8742 - val_loss: 22984.5547 - 371ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "79/79 - 0s - loss: 280.7853 - val_loss: 30793.6660 - 391ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "79/79 - 0s - loss: 265.0327 - val_loss: 22388.0059 - 438ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "79/79 - 0s - loss: 256.2534 - val_loss: 15819.6543 - 397ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "79/79 - 0s - loss: 275.7979 - val_loss: 25317.6113 - 373ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "79/79 - 0s - loss: 259.1424 - val_loss: 20369.6406 - 321ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "79/79 - 0s - loss: 268.0420 - val_loss: 21168.8496 - 316ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "79/79 - 1s - loss: 253.1475 - val_loss: 24495.0449 - 656ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "79/79 - 1s - loss: 260.0771 - val_loss: 29939.7559 - 813ms/epoch - 10ms/step\n",
      "Epoch 16: early stopping\n",
      "Epoch 1/100\n",
      "79/79 - 2s - loss: 71562.0000 - val_loss: 520662.5000 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 11116.4004 - val_loss: 409229.8125 - 377ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 0s - loss: 2769.5129 - val_loss: 122125.6172 - 376ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 1018.4091 - val_loss: 74155.9609 - 391ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 537.2886 - val_loss: 39889.7773 - 396ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 348.6497 - val_loss: 40448.3516 - 374ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 330.3423 - val_loss: 22482.0566 - 381ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 298.7671 - val_loss: 14117.7422 - 374ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "79/79 - 0s - loss: 287.7432 - val_loss: 21837.0586 - 338ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "79/79 - 0s - loss: 280.6654 - val_loss: 22699.0078 - 389ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "79/79 - 1s - loss: 273.0681 - val_loss: 18983.4570 - 502ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "79/79 - 1s - loss: 266.3138 - val_loss: 20069.2500 - 507ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "79/79 - 0s - loss: 255.0813 - val_loss: 23687.7949 - 366ms/epoch - 5ms/step\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/100\n",
      "79/79 - 2s - loss: 73243.7422 - val_loss: 638777.9375 - 2s/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 1s - loss: 16149.5020 - val_loss: 789912.8125 - 1s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 1s - loss: 3451.1843 - val_loss: 138783.1406 - 503ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 1478.9886 - val_loss: 87845.2656 - 409ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 737.6846 - val_loss: 58470.3281 - 396ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 467.9479 - val_loss: 30297.7051 - 410ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 381.4268 - val_loss: 14347.1172 - 390ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 322.3853 - val_loss: 13730.1484 - 378ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "79/79 - 0s - loss: 298.8235 - val_loss: 13162.8252 - 379ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "79/79 - 0s - loss: 286.8120 - val_loss: 10311.9961 - 383ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "79/79 - 0s - loss: 279.1238 - val_loss: 11436.2939 - 309ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "79/79 - 0s - loss: 278.9857 - val_loss: 7013.1904 - 363ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "79/79 - 0s - loss: 272.3614 - val_loss: 15666.4912 - 389ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "79/79 - 0s - loss: 259.1768 - val_loss: 7774.4961 - 373ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "79/79 - 0s - loss: 277.5299 - val_loss: 16539.6895 - 342ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "79/79 - 1s - loss: 256.5229 - val_loss: 5801.6069 - 511ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "79/79 - 0s - loss: 259.9409 - val_loss: 5268.7432 - 383ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "79/79 - 0s - loss: 225.9444 - val_loss: 9769.2939 - 343ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "79/79 - 0s - loss: 247.0171 - val_loss: 7126.3159 - 364ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "79/79 - 0s - loss: 236.8724 - val_loss: 6783.8315 - 372ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "79/79 - 0s - loss: 236.8902 - val_loss: 4385.3096 - 396ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "79/79 - 0s - loss: 259.4487 - val_loss: 5273.3740 - 345ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "79/79 - 0s - loss: 238.8629 - val_loss: 16446.6309 - 343ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "79/79 - 0s - loss: 265.6578 - val_loss: 4854.7803 - 321ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "79/79 - 0s - loss: 249.2997 - val_loss: 10607.0508 - 318ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "79/79 - 0s - loss: 224.5466 - val_loss: 3853.0803 - 438ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "79/79 - 1s - loss: 256.7949 - val_loss: 9791.7607 - 684ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "79/79 - 0s - loss: 232.7086 - val_loss: 6446.8955 - 353ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "79/79 - 1s - loss: 258.7946 - val_loss: 5727.7583 - 502ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "79/79 - 0s - loss: 236.1757 - val_loss: 5976.7612 - 338ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "79/79 - 0s - loss: 223.0881 - val_loss: 8604.7451 - 316ms/epoch - 4ms/step\n",
      "Epoch 31: early stopping\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "Model: 3\n",
      "Score (RMSE): 62.07318412328629\n",
      "R2: 0.9135138832764134\n",
      "MSE: 3853.080187203401\n",
      "5\n",
      "Epoch 1/100\n",
      "79/79 - 5s - loss: 60297.4844 - val_loss: 2561612.0000 - 5s/epoch - 57ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 1s - loss: 5618.8486 - val_loss: 210316.2188 - 954ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 1s - loss: 1643.4592 - val_loss: 122690.8594 - 546ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 760.4909 - val_loss: 66498.5781 - 498ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 1s - loss: 396.1333 - val_loss: 60183.7383 - 511ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 362.1489 - val_loss: 58895.5508 - 499ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 1s - loss: 316.3674 - val_loss: 43051.0312 - 612ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 1s - loss: 291.2737 - val_loss: 60287.3164 - 513ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "79/79 - 1s - loss: 324.7587 - val_loss: 67083.4609 - 516ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "79/79 - 1s - loss: 346.2421 - val_loss: 39192.5078 - 705ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "79/79 - 1s - loss: 298.6360 - val_loss: 39095.9219 - 514ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "79/79 - 0s - loss: 289.4528 - val_loss: 43619.7305 - 460ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "79/79 - 0s - loss: 268.2504 - val_loss: 39337.4414 - 467ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "79/79 - 1s - loss: 279.6680 - val_loss: 35849.4648 - 547ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "79/79 - 1s - loss: 272.2203 - val_loss: 56435.6719 - 570ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "79/79 - 1s - loss: 283.9563 - val_loss: 22757.2910 - 557ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "79/79 - 0s - loss: 292.1945 - val_loss: 61030.2422 - 485ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "79/79 - 0s - loss: 285.7505 - val_loss: 23254.6016 - 478ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "79/79 - 1s - loss: 300.7184 - val_loss: 25604.5566 - 500ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "79/79 - 1s - loss: 309.0408 - val_loss: 38377.3398 - 603ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "79/79 - 1s - loss: 284.2217 - val_loss: 18194.6738 - 507ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "79/79 - 0s - loss: 276.9805 - val_loss: 45281.4336 - 485ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "79/79 - 0s - loss: 247.6270 - val_loss: 19471.2617 - 484ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "79/79 - 0s - loss: 291.6703 - val_loss: 20362.5508 - 471ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "79/79 - 0s - loss: 271.0029 - val_loss: 32013.3555 - 450ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "79/79 - 0s - loss: 257.9156 - val_loss: 21510.9160 - 477ms/epoch - 6ms/step\n",
      "Epoch 26: early stopping\n",
      "Epoch 1/100\n",
      "79/79 - 4s - loss: 61014.3203 - val_loss: 2052590.0000 - 4s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 1s - loss: 4610.0557 - val_loss: 140478.8594 - 566ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 1s - loss: 1309.8536 - val_loss: 129782.0078 - 514ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 680.4855 - val_loss: 57618.6992 - 471ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 392.9324 - val_loss: 31880.7793 - 481ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 403.9059 - val_loss: 25010.2168 - 491ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 376.6760 - val_loss: 14411.6074 - 479ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 322.7646 - val_loss: 14093.9961 - 445ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "79/79 - 0s - loss: 311.3986 - val_loss: 26750.2832 - 473ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "79/79 - 0s - loss: 310.0896 - val_loss: 9459.4414 - 478ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "79/79 - 0s - loss: 295.0463 - val_loss: 15696.5664 - 430ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "79/79 - 0s - loss: 305.3561 - val_loss: 31001.5566 - 426ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "79/79 - 1s - loss: 277.6030 - val_loss: 19403.3223 - 590ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "79/79 - 0s - loss: 269.0563 - val_loss: 16319.2695 - 487ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "79/79 - 1s - loss: 285.9487 - val_loss: 8572.3809 - 594ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "79/79 - 0s - loss: 270.5246 - val_loss: 7581.2490 - 458ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "79/79 - 0s - loss: 298.7069 - val_loss: 2939.5029 - 429ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "79/79 - 0s - loss: 316.8405 - val_loss: 15040.7803 - 425ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "79/79 - 1s - loss: 327.9445 - val_loss: 12013.5264 - 504ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "79/79 - 0s - loss: 269.3988 - val_loss: 11474.3643 - 441ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "79/79 - 0s - loss: 272.2801 - val_loss: 10087.6035 - 442ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "79/79 - 0s - loss: 284.6290 - val_loss: 9851.3701 - 440ms/epoch - 6ms/step\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/100\n",
      "79/79 - 3s - loss: 61482.2734 - val_loss: 1997917.6250 - 3s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 6779.8701 - val_loss: 339366.8125 - 473ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "79/79 - 1s - loss: 1928.6177 - val_loss: 171413.9219 - 515ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "79/79 - 1s - loss: 794.4344 - val_loss: 83445.7578 - 514ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 441.0883 - val_loss: 65975.6953 - 498ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 442.1174 - val_loss: 86629.1797 - 473ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 334.6735 - val_loss: 45598.0742 - 481ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "79/79 - 1s - loss: 332.5403 - val_loss: 48923.6055 - 542ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "79/79 - 0s - loss: 295.2945 - val_loss: 55594.5430 - 457ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "79/79 - 1s - loss: 275.8766 - val_loss: 44366.8242 - 650ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "79/79 - 0s - loss: 303.0980 - val_loss: 53712.2578 - 437ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "79/79 - 1s - loss: 277.4962 - val_loss: 33361.8359 - 545ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "79/79 - 1s - loss: 268.5308 - val_loss: 29027.9316 - 503ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "79/79 - 0s - loss: 303.5329 - val_loss: 42499.7422 - 484ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "79/79 - 1s - loss: 286.3872 - val_loss: 35984.5391 - 525ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "79/79 - 1s - loss: 261.0271 - val_loss: 48253.9844 - 521ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "79/79 - 1s - loss: 275.7987 - val_loss: 37500.1133 - 518ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "79/79 - 1s - loss: 267.9877 - val_loss: 31943.2656 - 534ms/epoch - 7ms/step\n",
      "Epoch 18: early stopping\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "Model: 5\n",
      "Score (RMSE): 170.37585259344394\n",
      "R2: 0.34800104024045253\n",
      "MSE: 29027.931146942938\n",
      "7\n",
      "Epoch 1/100\n",
      "78/78 - 2s - loss: 49368.0078 - val_loss: 1546321.1250 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 3833.9805 - val_loss: 159064.4219 - 596ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 1042.7219 - val_loss: 123109.2422 - 549ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 470.5718 - val_loss: 102532.8047 - 578ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 411.7727 - val_loss: 84068.6641 - 547ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 380.6512 - val_loss: 84400.2969 - 502ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 352.8640 - val_loss: 83671.4766 - 560ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 365.4055 - val_loss: 63242.4922 - 691ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 0s - loss: 337.8427 - val_loss: 79765.0938 - 486ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 356.0893 - val_loss: 75189.0156 - 518ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 331.8084 - val_loss: 89386.9219 - 553ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 315.9286 - val_loss: 54350.7539 - 574ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 301.1757 - val_loss: 55658.4023 - 518ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 0s - loss: 328.9320 - val_loss: 75242.5938 - 478ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 382.0959 - val_loss: 69443.2422 - 513ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 329.6153 - val_loss: 47669.6367 - 610ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 1s - loss: 331.2244 - val_loss: 55446.9297 - 681ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 1s - loss: 308.0355 - val_loss: 60689.6719 - 617ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 1s - loss: 289.3106 - val_loss: 56261.4062 - 591ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 1s - loss: 373.4287 - val_loss: 47121.2344 - 709ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 1s - loss: 274.2585 - val_loss: 79117.2656 - 542ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "78/78 - 1s - loss: 300.3215 - val_loss: 68441.8047 - 597ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "78/78 - 1s - loss: 269.9671 - val_loss: 77532.2812 - 512ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "78/78 - 1s - loss: 323.2842 - val_loss: 77933.5234 - 520ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "78/78 - 1s - loss: 314.6136 - val_loss: 103346.4297 - 512ms/epoch - 7ms/step\n",
      "Epoch 25: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 4s - loss: 59735.9727 - val_loss: 716702.3750 - 4s/epoch - 48ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 6414.3452 - val_loss: 519240.0312 - 556ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 1603.6229 - val_loss: 212189.2969 - 578ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 664.2206 - val_loss: 143962.4844 - 680ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 483.0554 - val_loss: 162201.3750 - 522ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 437.8621 - val_loss: 100349.2344 - 550ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 405.2330 - val_loss: 114576.3750 - 531ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 326.5515 - val_loss: 82794.1484 - 571ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 311.4957 - val_loss: 105110.7188 - 665ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 355.3922 - val_loss: 73541.2344 - 513ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 0s - loss: 323.1410 - val_loss: 89306.5312 - 497ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 324.5997 - val_loss: 73506.6719 - 607ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 350.0832 - val_loss: 104070.5547 - 547ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 0s - loss: 306.5779 - val_loss: 86375.4766 - 495ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 306.4005 - val_loss: 64830.2383 - 566ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 294.7781 - val_loss: 99418.0000 - 504ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 1s - loss: 304.4809 - val_loss: 64574.3125 - 600ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 1s - loss: 296.9028 - val_loss: 44220.8203 - 656ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 1s - loss: 287.4607 - val_loss: 78494.4688 - 517ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 0s - loss: 305.9721 - val_loss: 79477.6719 - 474ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 1s - loss: 283.3871 - val_loss: 56187.2852 - 547ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "78/78 - 1s - loss: 295.8275 - val_loss: 62096.7969 - 581ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "78/78 - 1s - loss: 285.8219 - val_loss: 66537.7891 - 554ms/epoch - 7ms/step\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 4s - loss: 52622.5820 - val_loss: 799632.9375 - 4s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 3165.9214 - val_loss: 275398.1875 - 570ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 809.0963 - val_loss: 177754.6406 - 632ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 479.8815 - val_loss: 53361.5508 - 534ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 421.0557 - val_loss: 79378.2891 - 522ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 377.1754 - val_loss: 46331.4766 - 546ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 350.1882 - val_loss: 45261.8047 - 614ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 375.1862 - val_loss: 34886.6133 - 605ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 293.8580 - val_loss: 25700.2773 - 585ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 287.5629 - val_loss: 29536.7363 - 556ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 335.1771 - val_loss: 37413.1016 - 541ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 0s - loss: 326.7163 - val_loss: 39654.6992 - 476ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 305.2403 - val_loss: 47086.6211 - 559ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 320.7612 - val_loss: 32905.7461 - 592ms/epoch - 8ms/step\n",
      "Epoch 14: early stopping\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "Model: 7\n",
      "Score (RMSE): 160.31305352139623\n",
      "R2: 0.4223516190798964\n",
      "MSE: 25700.27512935405\n",
      "9\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 55998.5000 - val_loss: 3838079.7500 - 3s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 4224.0059 - val_loss: 200564.5625 - 732ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 668.6265 - val_loss: 145887.2656 - 684ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 505.5392 - val_loss: 98722.6641 - 712ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 415.8781 - val_loss: 133101.4062 - 734ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 378.5631 - val_loss: 125328.6094 - 857ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 393.7330 - val_loss: 127985.1016 - 749ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 388.4330 - val_loss: 94340.2734 - 688ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 433.2537 - val_loss: 128691.7109 - 620ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 354.8629 - val_loss: 131360.7500 - 667ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 342.0648 - val_loss: 124684.5391 - 745ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 324.2246 - val_loss: 78471.2969 - 723ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 384.3301 - val_loss: 130914.2109 - 757ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 327.5352 - val_loss: 109762.4141 - 783ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 320.4976 - val_loss: 133778.3594 - 679ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 313.4511 - val_loss: 76863.6406 - 754ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 1s - loss: 324.3598 - val_loss: 84785.5156 - 723ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 1s - loss: 316.7463 - val_loss: 116024.7969 - 653ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 1s - loss: 326.6009 - val_loss: 114398.4375 - 715ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 1s - loss: 334.3778 - val_loss: 111365.1484 - 639ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 1s - loss: 294.9929 - val_loss: 138409.7812 - 883ms/epoch - 11ms/step\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 48361.4375 - val_loss: 426684.9375 - 3s/epoch - 39ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 2908.1008 - val_loss: 191063.9844 - 705ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 859.8045 - val_loss: 221684.3750 - 742ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 639.4766 - val_loss: 62778.6094 - 913ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 464.8788 - val_loss: 67154.7812 - 738ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 491.7141 - val_loss: 70005.4688 - 683ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 397.4667 - val_loss: 61032.9883 - 684ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 351.0676 - val_loss: 61662.1406 - 841ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 414.3557 - val_loss: 59273.6016 - 766ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 373.9342 - val_loss: 52384.1758 - 785ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 335.4743 - val_loss: 73114.9922 - 996ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 361.1584 - val_loss: 52672.4375 - 800ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 309.4842 - val_loss: 45250.6289 - 715ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 351.3105 - val_loss: 38192.0938 - 865ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 337.7773 - val_loss: 47663.7500 - 731ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 351.8029 - val_loss: 49932.0508 - 685ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 1s - loss: 286.4114 - val_loss: 36558.4102 - 1s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 1s - loss: 336.7409 - val_loss: 53414.6914 - 778ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 1s - loss: 370.3110 - val_loss: 37632.4805 - 678ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 1s - loss: 322.8711 - val_loss: 53000.8086 - 729ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 1s - loss: 295.4961 - val_loss: 61619.0859 - 685ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "78/78 - 1s - loss: 335.9856 - val_loss: 69180.8984 - 721ms/epoch - 9ms/step\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 49046.4844 - val_loss: 916242.5625 - 3s/epoch - 39ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 3018.1062 - val_loss: 245940.2656 - 667ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 701.9157 - val_loss: 102426.4922 - 680ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 487.6093 - val_loss: 103778.0859 - 632ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 392.8552 - val_loss: 73685.4219 - 693ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 369.2428 - val_loss: 99833.7422 - 832ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 415.2616 - val_loss: 82402.9766 - 658ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 410.7644 - val_loss: 74420.1797 - 636ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 386.5033 - val_loss: 93395.1797 - 648ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 389.4542 - val_loss: 130800.8281 - 591ms/epoch - 8ms/step\n",
      "Epoch 10: early stopping\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "Model: 9\n",
      "Score (RMSE): 271.4505993909707\n",
      "R2: -0.6573518380616892\n",
      "MSE: 73685.42790971725\n",
      "11\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 53181.9609 - val_loss: 689147.8125 - 3s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 3460.3835 - val_loss: 75696.7969 - 770ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 730.0601 - val_loss: 55450.0039 - 846ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 502.9061 - val_loss: 25029.9277 - 762ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 470.5615 - val_loss: 55395.7773 - 813ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 449.2039 - val_loss: 40284.6094 - 891ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 504.4854 - val_loss: 38825.9570 - 734ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 416.5968 - val_loss: 13805.4033 - 826ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 369.7523 - val_loss: 25611.5293 - 735ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 449.9947 - val_loss: 40273.3320 - 754ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 404.8233 - val_loss: 21011.0312 - 819ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 382.3658 - val_loss: 27621.2402 - 827ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 360.8079 - val_loss: 22515.3828 - 796ms/epoch - 10ms/step\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 47002.3867 - val_loss: 384842.3438 - 3s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 2626.8125 - val_loss: 120021.7109 - 783ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 635.7488 - val_loss: 34742.3633 - 921ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 414.2660 - val_loss: 22161.7129 - 790ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 475.5914 - val_loss: 12175.8369 - 900ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 424.8351 - val_loss: 27472.8457 - 1s/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 332.8854 - val_loss: 35527.8125 - 742ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 354.3851 - val_loss: 37917.4648 - 753ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 482.1710 - val_loss: 23913.4766 - 766ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 372.5762 - val_loss: 35834.7188 - 747ms/epoch - 10ms/step\n",
      "Epoch 10: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 48905.1016 - val_loss: 237993.1406 - 3s/epoch - 39ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 3672.2649 - val_loss: 37926.9336 - 914ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 1046.1154 - val_loss: 41463.4727 - 828ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 529.3227 - val_loss: 25794.6895 - 970ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 518.0376 - val_loss: 23226.9375 - 780ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 509.6877 - val_loss: 44780.4414 - 890ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 446.5905 - val_loss: 8474.9297 - 861ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 416.9324 - val_loss: 9070.7930 - 767ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 407.7182 - val_loss: 21471.9570 - 851ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 426.8295 - val_loss: 5564.0732 - 1s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 349.4234 - val_loss: 39115.1875 - 787ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 369.2049 - val_loss: 6698.4917 - 828ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 370.7248 - val_loss: 14826.8418 - 809ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 335.0928 - val_loss: 11261.8584 - 765ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 350.8755 - val_loss: 11913.4990 - 862ms/epoch - 11ms/step\n",
      "Epoch 15: early stopping\n",
      "34/34 [==============================] - 1s 7ms/step\n",
      "Model: 11\n",
      "Score (RMSE): 74.59271975772492\n",
      "R2: 0.87478541204559\n",
      "MSE: 5564.073840854486\n",
      "13\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 47626.1250 - val_loss: 129394.0859 - 3s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 1669.3325 - val_loss: 7597.1929 - 922ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 726.2103 - val_loss: 10558.5029 - 1s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 666.7957 - val_loss: 1388.8756 - 1s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 459.3491 - val_loss: 2601.9656 - 860ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 482.9320 - val_loss: 2090.6980 - 863ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 471.4322 - val_loss: 2253.2134 - 828ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 428.4049 - val_loss: 5366.4258 - 928ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 455.6684 - val_loss: 4055.3857 - 970ms/epoch - 12ms/step\n",
      "Epoch 9: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 53054.8516 - val_loss: 891631.0625 - 3s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 2586.8555 - val_loss: 53489.1133 - 915ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 1002.3481 - val_loss: 34842.7578 - 938ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 675.2852 - val_loss: 32408.8750 - 968ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 596.8810 - val_loss: 20869.1055 - 939ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 533.3789 - val_loss: 25327.6953 - 865ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 460.7394 - val_loss: 24116.9688 - 1s/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 471.2097 - val_loss: 10262.5771 - 899ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 417.9305 - val_loss: 9833.1172 - 1s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 414.1778 - val_loss: 4585.9419 - 1s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 421.9097 - val_loss: 2372.3892 - 909ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 407.0648 - val_loss: 7085.1577 - 1s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 366.8101 - val_loss: 2583.4465 - 880ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 355.1716 - val_loss: 5027.6748 - 948ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 414.4926 - val_loss: 4748.0098 - 905ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 365.1393 - val_loss: 6852.4604 - 848ms/epoch - 11ms/step\n",
      "Epoch 16: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 36782.0625 - val_loss: 4365.1768 - 3s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 952.0323 - val_loss: 11517.0928 - 916ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 543.6630 - val_loss: 7676.2197 - 919ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 586.6100 - val_loss: 4969.3354 - 1s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 501.9885 - val_loss: 4988.5234 - 1s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 455.6911 - val_loss: 3646.4478 - 1s/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 502.9901 - val_loss: 13077.3223 - 950ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 368.3273 - val_loss: 6474.1147 - 877ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 370.8235 - val_loss: 4742.7324 - 984ms/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 332.6288 - val_loss: 4547.9448 - 1s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 321.7571 - val_loss: 4002.4827 - 1s/epoch - 13ms/step\n",
      "Epoch 11: early stopping\n",
      "34/34 [==============================] - 0s 4ms/step\n",
      "Model: 13\n",
      "Score (RMSE): 60.38582329469254\n",
      "R2: 0.9179007525656003\n",
      "MSE: 3646.447654977833\n",
      "15\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 62290.1367 - val_loss: 2678247.0000 - 3s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 3623.8328 - val_loss: 54063.7461 - 1s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 827.8724 - val_loss: 1682.4623 - 1s/epoch - 15ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 676.3118 - val_loss: 18154.4355 - 1s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 633.3640 - val_loss: 5169.3110 - 938ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 598.9404 - val_loss: 5453.8394 - 1s/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 578.9289 - val_loss: 4819.8892 - 1s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 517.2662 - val_loss: 4665.6001 - 1s/epoch - 13ms/step\n",
      "Epoch 8: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 39118.8984 - val_loss: 58643.3789 - 3s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 1645.7122 - val_loss: 37852.8789 - 1s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 684.7703 - val_loss: 8276.0791 - 1s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 560.5618 - val_loss: 5233.0352 - 1s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 531.4342 - val_loss: 15395.2676 - 1000ms/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 530.6253 - val_loss: 18791.1582 - 947ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 582.6301 - val_loss: 3126.0974 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 458.3532 - val_loss: 1722.7074 - 1s/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 397.6212 - val_loss: 1807.7155 - 1s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 485.8973 - val_loss: 1750.5223 - 928ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 470.7954 - val_loss: 1676.4618 - 986ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 491.0909 - val_loss: 6172.9639 - 953ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 444.9193 - val_loss: 1828.6305 - 1s/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 389.3494 - val_loss: 2271.0620 - 998ms/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 377.9157 - val_loss: 2582.1162 - 966ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 434.7379 - val_loss: 1534.3971 - 1s/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 1s - loss: 364.5947 - val_loss: 1809.2997 - 1s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 1s - loss: 488.4086 - val_loss: 16092.8584 - 1s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 1s - loss: 427.1589 - val_loss: 8802.4766 - 1s/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 1s - loss: 349.8925 - val_loss: 4674.3906 - 973ms/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 1s - loss: 406.7756 - val_loss: 6489.3525 - 975ms/epoch - 12ms/step\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 47209.2969 - val_loss: 327345.0625 - 3s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 1949.7969 - val_loss: 5470.1284 - 1s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 958.7578 - val_loss: 39129.0781 - 948ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 944.1592 - val_loss: 51713.9492 - 931ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 601.5226 - val_loss: 35839.7109 - 1s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 570.2213 - val_loss: 42363.8438 - 1s/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 537.0453 - val_loss: 46975.8438 - 947ms/epoch - 12ms/step\n",
      "Epoch 7: early stopping\n",
      "34/34 [==============================] - 0s 4ms/step\n",
      "Model: 15\n",
      "Score (RMSE): 73.96032086449979\n",
      "R2: 0.8767998741276557\n",
      "MSE: 5470.129062379763\n",
      "17\n",
      "Epoch 1/100\n",
      "78/78 - 3s - loss: 55401.1328 - val_loss: 1268164.8750 - 3s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 1s - loss: 5498.6948 - val_loss: 622837.0000 - 1s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 1s - loss: 891.9076 - val_loss: 147191.8750 - 1s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 1s - loss: 604.4230 - val_loss: 119271.8438 - 1s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 1s - loss: 508.1993 - val_loss: 168561.9688 - 1s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 1s - loss: 530.1953 - val_loss: 231487.9688 - 1s/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 1s - loss: 554.6539 - val_loss: 112603.0391 - 1s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 1s - loss: 480.9707 - val_loss: 158788.5469 - 1s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 1s - loss: 521.2548 - val_loss: 119993.6641 - 1s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 1s - loss: 437.9378 - val_loss: 120366.8125 - 1s/epoch - 15ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 1s - loss: 473.2364 - val_loss: 97439.3047 - 1s/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 1s - loss: 464.8558 - val_loss: 136954.8125 - 1s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 1s - loss: 392.4976 - val_loss: 137833.8281 - 1s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 1s - loss: 465.5377 - val_loss: 140987.4844 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 1s - loss: 402.3919 - val_loss: 85157.0234 - 1s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 1s - loss: 493.6153 - val_loss: 112914.4297 - 1s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 1s - loss: 471.5974 - val_loss: 104317.6797 - 1s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 1s - loss: 448.6395 - val_loss: 66499.5781 - 1s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 2s - loss: 397.5459 - val_loss: 50773.0898 - 2s/epoch - 26ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 2s - loss: 466.7061 - val_loss: 44576.8008 - 2s/epoch - 22ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 1s - loss: 392.8928 - val_loss: 29698.1445 - 1s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "78/78 - 1s - loss: 372.2450 - val_loss: 26168.8418 - 1s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "78/78 - 1s - loss: 418.8241 - val_loss: 21002.7949 - 1s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "78/78 - 1s - loss: 406.3365 - val_loss: 12626.0166 - 1s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "78/78 - 1s - loss: 345.2163 - val_loss: 12440.5654 - 1s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "78/78 - 1s - loss: 379.5901 - val_loss: 16905.9395 - 1s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "78/78 - 2s - loss: 319.4091 - val_loss: 10404.3066 - 2s/epoch - 24ms/step\n",
      "Epoch 28/100\n",
      "78/78 - 1s - loss: 429.7857 - val_loss: 14139.4131 - 1s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "78/78 - 1s - loss: 325.0677 - val_loss: 7008.6772 - 1s/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "78/78 - 1s - loss: 338.8655 - val_loss: 16037.1416 - 1s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "78/78 - 1s - loss: 412.6465 - val_loss: 2331.4343 - 1s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "78/78 - 1s - loss: 319.6268 - val_loss: 5527.3281 - 1s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "78/78 - 1s - loss: 284.8553 - val_loss: 5082.9824 - 1s/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "78/78 - 1s - loss: 331.2597 - val_loss: 1484.2429 - 1s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "78/78 - 1s - loss: 394.6023 - val_loss: 1227.1055 - 1s/epoch - 15ms/step\n",
      "Epoch 36/100\n",
      "78/78 - 1s - loss: 379.3552 - val_loss: 16467.9902 - 1s/epoch - 15ms/step\n",
      "Epoch 37/100\n",
      "78/78 - 1s - loss: 297.5030 - val_loss: 2196.8015 - 1s/epoch - 19ms/step\n",
      "Epoch 38/100\n",
      "78/78 - 1s - loss: 339.4598 - val_loss: 3704.6106 - 1s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "78/78 - 1s - loss: 383.5924 - val_loss: 10118.4600 - 1s/epoch - 19ms/step\n",
      "Epoch 40/100\n",
      "78/78 - 1s - loss: 351.9898 - val_loss: 1749.2727 - 1s/epoch - 16ms/step\n",
      "Epoch 40: early stopping\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     monitor \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39mfileName, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(fileName)\n\u001b[0;32m     32\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileg19sdlfq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py:1146\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1315\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1311\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1314\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2891\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2891\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3692\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3691\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py:1135\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1135\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py:997\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:634\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    632\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes(\n\u001b[0;32m    639\u001b[0m     [\n\u001b[0;32m    640\u001b[0m         v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m     ]\n\u001b[0;32m    644\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:510\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    509\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:393\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# We compute the gradient for the sub-graph between trainable ys and xs\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# with non-None incoming gradients. We later pad the None's to the list of\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# outputs.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m ys, xs, non_none_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[(y, x, grad) \u001b[38;5;28;01mfor\u001b[39;00m (y, x, grad) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    391\u001b[0m     body_graph\u001b[38;5;241m.\u001b[39moutputs, body_graph\u001b[38;5;241m.\u001b[39minputs, grads) \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m--> 393\u001b[0m body_grad_graph, args \u001b[38;5;241m=\u001b[39m \u001b[43m_create_grad_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_none_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_grad_fn_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstateful_parallelism\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m body_grad_graph\u001b[38;5;241m.\u001b[39mwhile_op_needs_rewrite:\n\u001b[0;32m    399\u001b[0m   \u001b[38;5;66;03m# Modify 'op' to output the intermediate accumulators needed by the grad\u001b[39;00m\n\u001b[0;32m    400\u001b[0m   \u001b[38;5;66;03m# function.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m   \u001b[38;5;66;03m# NOTE(skyewm): if there are any active sessions, this modification to `op`\u001b[39;00m\n\u001b[0;32m    402\u001b[0m   \u001b[38;5;66;03m# may make them unrunnable!\u001b[39;00m\n\u001b[0;32m    404\u001b[0m   cond_graph\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_rewritten\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:695\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[1;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[0;32m    692\u001b[0m args \u001b[38;5;241m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m grad_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhile_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbody_graph_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43macd_record_initial_resource_uses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstateful_parallelism\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph\u001b[38;5;241m.\u001b[39mcaptures:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:697\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    692\u001b[0m args \u001b[38;5;241m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m grad_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    696\u001b[0m     name,\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    698\u001b[0m     args, {},\n\u001b[0;32m    699\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[0;32m    700\u001b[0m                                        maximum_iterations, while_op,\n\u001b[0;32m    701\u001b[0m                                        body_graph_inputs, body_graph_outputs),\n\u001b[0;32m    702\u001b[0m     acd_record_initial_resource_uses\u001b[38;5;241m=\u001b[39mstateful_parallelism)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph\u001b[38;5;241m.\u001b[39mcaptures:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:753\u001b[0m, in \u001b[0;36m_grad_fn\u001b[1;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[0;32m    746\u001b[0m grad_ys \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;66;03m# TODO(srbs): Mark GradientsHelper as public?\u001b[39;00m\n\u001b[1;32m--> 753\u001b[0m grad_outs \u001b[38;5;241m=\u001b[39m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;66;03m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;66;03m# is a tf.StopGradient in the loop body.\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad_outs)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m \u001b[43m_MaybeCompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    326\u001b[0m     xla_compile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xla_compile:\n\u001b[1;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exit early\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# together with the non-gradient computation.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 696\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    697\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1736\u001b[0m, in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1734\u001b[0m b \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mconj(op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_b:\n\u001b[1;32m-> 1736\u001b[0m   grad_a \u001b[38;5;241m=\u001b[39m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1737\u001b[0m   grad_b \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmat_mul(a, grad, transpose_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m t_b:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6033\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6031\u001b[0m   transpose_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   6032\u001b[0m transpose_b \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_bool(transpose_b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose_b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6033\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6034\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMatMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6035\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6036\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   6037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1044\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (op_type \u001b[38;5;129;01min\u001b[39;00m optimized_reduction_ops \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39moutput_all_intermediates() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39mgraph_wrapped_for_higher_order_tape_gradients(\n\u001b[0;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph)):\n\u001b[0;32m   1034\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_op_to_forward_graph(\n\u001b[0;32m   1035\u001b[0m       op_type,\n\u001b[0;32m   1036\u001b[0m       inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m       op_def\u001b[38;5;241m=\u001b[39mop_def,\n\u001b[0;32m   1042\u001b[0m       compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m-> 1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:733\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    731\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ctxt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ctxt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddValue\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    732\u001b[0m     inp \u001b[38;5;241m=\u001b[39m ctxt\u001b[38;5;241m.\u001b[39mAddValue(inp)\n\u001b[1;32m--> 733\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(FuncGraph, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:800\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    790\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInaccessibleTensorError(\n\u001b[0;32m    791\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is out of scope and cannot be used here. Use return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, explicit Python locals or TensorFlow collections to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    797\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m cannot be accessed from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    798\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit was defined in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is out of scope.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    799\u001b[0m     inner_graph \u001b[38;5;241m=\u001b[39m inner_graph\u001b[38;5;241m.\u001b[39mouter_graph\n\u001b[1;32m--> 800\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1207\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._capture_helper\u001b[1;34m(self, tensor, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph\u001b[38;5;241m.\u001b[39mouter_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m   1206\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39mclear_control_inputs():\n\u001b[1;32m-> 1207\u001b[0m     tensor_list \u001b[38;5;241m=\u001b[39m \u001b[43mlist_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_tensor_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_build_accumulator_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_inputs\u001b[38;5;241m.\u001b[39mappend(tensor_list)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# Push the intermediate tensor to the tensor list. This captures\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# `tensor_list`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\list_ops.py:54\u001b[0m, in \u001b[0;36mempty_tensor_list\u001b[1;34m(element_shape, element_dtype, max_num_elements, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_num_elements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   max_num_elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_list_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_tensor_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_build_element_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_list_ops.py:62\u001b[0m, in \u001b[0;36mempty_tensor_list\u001b[1;34m(element_shape, max_num_elements, element_dtype, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m element_dtype \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_type(element_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melement_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEmptyTensorList\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                         \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:756\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_op_helper\u001b[39m(op_type_name, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeywords):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of apply_op that returns output_structure, op.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m   op_def, g, producer \u001b[38;5;241m=\u001b[39m \u001b[43m_GetOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m   name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m op_type_name\n\u001b[0;32m    759\u001b[0m   attrs, attr_protos \u001b[38;5;241m=\u001b[39m {}, {}\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:736\u001b[0m, in \u001b[0;36m_GetOpDef\u001b[1;34m(op_type_name, keywords)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    733\u001b[0m   \u001b[38;5;66;03m# Need to flatten all the arguments into a list.\u001b[39;00m\n\u001b[0;32m    734\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    735\u001b[0m   g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_get_graph_from_inputs(_Flatten(keywords\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m--> 736\u001b[0m   producer \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def_versions\u001b[49m\u001b[38;5;241m.\u001b[39mproducer\n\u001b[0;32m    737\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3421\u001b[0m, in \u001b[0;36mGraph.graph_def_versions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:\n\u001b[0;32m   3420\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 3421\u001b[0m     \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphVersions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3422\u001b[0m   data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n\u001b[0;32m   3423\u001b[0m version_def \u001b[38;5;241m=\u001b[39m versions_pb2\u001b[38;5;241m.\u001b[39mVersionDef()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "step = 2\n",
    "j = 1\n",
    "while j < 200:\n",
    "    print(j)\n",
    "    SEQUENCE_SIZE = j\n",
    "    fileName= \"models/lstm_checkpoint_\" + str(j) + \".keras\"\n",
    "    x_train,y_train = to_sequences(SEQUENCE_SIZE, df_train)\n",
    "    x_test,y_test = to_sequences(SEQUENCE_SIZE, df_test)\n",
    "\n",
    "    model_dir = \"models\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    for i in range(3):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(LSTM(128, input_shape=(SEQUENCE_SIZE,5), activation=\"relu\"))\n",
    "        #model.add(Dropout(0.1))\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dropout(0.1))\n",
    "        #model.add(Dense(32))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "        monitor = EarlyStopping(monitor=\"val_loss\", min_delta=1e-3, patience=5, verbose=1, mode=\"auto\")\n",
    "        checkpointer = ModelCheckpoint(filepath=fileName, verbose=0, save_best_only=True)\n",
    "\n",
    "        model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor, checkpointer], verbose=2, epochs=100)  \n",
    "    \n",
    "    model.load_weights(fileName)\n",
    "    pred = model.predict(x_test)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    results.append(score)\n",
    "    print(\"Model: \" + str(j) + \"\\nScore (RMSE): {}\".format(score))\n",
    "    print(\"R2:\",metrics.r2_score(y_test,pred))\n",
    "    print(\"MSE:\", metrics.mean_squared_error(y_test, pred))\n",
    "    step = step * step\n",
    "    j += step\n",
    "minValue = min(results)\n",
    "minIndex = results.index(minValue) + 1\n",
    "print(\"The best number of days was: \" + str(minIndex)  + \"\\nThe RMSE was: \" + str(minValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
